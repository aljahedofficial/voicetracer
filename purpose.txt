Title: The Monolingualism of the Machine: Stylistic Homogenization in L2 Academic Writing
Objective:
This thesis examines how AI editing tools flatten the stylistic diversity of L2 academic writing. When non-native English speakers use these tools to improve grammar and fluency, their writing often converges toward a generic and machine-standard style. This is termed as "homogenization". Homogenization in language refers to the process of making linguistic varieties uniform or similar, often reducing diversity in dialects, vocabulary, or grammar across a speech community. This can occur through globalization, standardization via media/education, or dominant language spread, leading to a loss of local linguistic features. In ELT research, it relates to global English's role in reducing local varieties. The research aims to identify what gets lost in this process and whether that loss can be measured.
Specifically, the study will:
i. establish baseline profiles of authentic L2 writing voices through analysis of unassisted texts.
ii. track systematic replacements of individual stylistic markers with formulaic AI patterns.
iii. develop a prototype system for documenting voice retention during AI-assisted editing.
Problems the Thesis Will Address:
i. The removal of authentic L2 voice. Students gain grammatical correctness but lose the idiosyncratic features that mark their genuine linguistic identity.
ii. The false positive trap. AI-edited L2 writing often triggers detection systems because it lacks the irregularities typical of human writing.
iii. What leads the L2 learners' imitating the AI sentence pattern and structure.
iii. Lack of awareness of the L2 learners. Learners cannot preserve features they cannot see; current tools provide no feedback on voice loss.
iv. Institutional bias. Academic expectations often privilege a narrow standard of correct, formal and academic English over authentic L2 expression.
v. Absence of documentation. Students have no systematic method to demonstrate authorship when their AI-assisted work is questioned.
Rationale:
Recent research confirms that AI writing assistance homogenizes writing toward Western stylistic norms: in a cross-cultural study of 118 writers, Agarwal et al. (2024) found that Indian participants' writing converged toward American stylistic patterns when using AI suggestions, while Americans showed no significant change. Based on the aforementioned research, this thesis shifts focus from detecting AI use to preserving human voice. The central argument is that "standard" writing is not necessarily authentic writing, and that L2 learners need ways to use AI tools without becoming stylistically indistinguishable from them.
Theoretical Framework:
In the context of modern ELT, "learner autonomy" is often defined by the student's ability to take charge of their own learning process, utilizing digital resources to bridge the gap between their "interlanguage" and academic standards. Henri Holec (1981) first defined learner autonomy as "the ability to take charge of one's own learning." By using AI editing tools, L2 learners seem to exercise a high degree of autonomy; they are no longer dependent solely on human tutors or commercial grammar books to produce high-level academic writings. This technology enhancement has developed a way for the learners of L2 to gain agency over their final output. The learners not only use AI just to get answers but also to:
1. break down difficult topics before lectures.
2. ask deeper follow-up questions prompting Krashen's (1982) Comprehensible Input (i+1).
3. generate practice problems at different difficulty levels.
4. get feedback on ideas before submitting work.
5. get their assignment graded.
6. visualize the resource materials that supports Fleming's (1987) VARK model.
7. monitor their progress and performance which is based on Krashen's (1982) Monitor Hypothesis.
However, overreliance on the AI tools ultimately makes the learners mimic the AI structure. This leads directly into the "False Positive Trap". The "trap" occurs when the L2 learners use AI to achieve grammatical perfection but erases their own stylistic markers that define their genuine linguistic identity. Because these learners often lack "voice awareness," they cannot see the features they are losing. They "standardize" their authentic L2 voice for a "machine-standard" fluency and create a work that ensures accuracy but lacks the human traces, irregularities and "burstiness" that signal genuine authorship and voice. This is similar to moving toward "being" an AI tool, rather than improving the writing skills. The irony of this situation is profound. For example, the very tools which were meant to empower the L2 writer and give them a "voice" in the global academic community actually end up silencing their unique perspective and humanistic style. Consequently, the students themselves become an imitator of the AI itself. The ultimate irony is that the more "autonomous" the student believes they are being by self-editing with AI, the more they are actually conforming to a pre-determined, predictive and algorithmic pattern. This cycle results in "Stylistic Homogenization" which means systematic flattening of diversity in L2 writing. Authentic, unassisted writing voices are replaced by "standard AI patterns" and "statistical smoothness". Through this process, the writer becomes stylistically indistinguishable from the machine. This thesis argues that this homogenization is not a neutral improvement of grammar, but a "monolingualism of the machine" that treats the unique linguistic fingerprints of L2 scholars as errors to be smoothed away.
Methodology:
A. Data Collection
i. Baseline Texts
10 L2 English graduate students will complete a 30-minute proctored writing task (argumentative essay, 300 words, no AI assistance).
ii. AI-Edited Versions
The same texts will be processed through ChatGPT with the prompt: "Fix grammar and fluency only."
B. Stylistic Analysis
Analysis will be conducted via manual coding and existing tools:
* Burstiness: Sentence length standard deviation ÷ mean (calculated via Excel/Python)
* AI-ism Inventory: Formulaic markers (e.g., "delve into," "it is important to note," "in conclusion") catalogued through systematic text comparison
* Lexical Diversity: MTLD or TTR via existing tools (e.g., VocabProfile, AntWordProfiler)
* Syntactic Complexity: Average sentence length, subordination ratio (manual coding)
C. Prototype Development
A lightweight Streamlit webapp deployed on Streamlit Cloud (free, no installation for users) will be developed to:
* Input original and AI-edited texts
* Display side-by-side comparison
* Calculate and visualize burstiness and AI-ism frequency
* Generate simple PDF reports
Development scope: ~2-3 weeks.
D. Validation
Pilot testing with the same 10 participants:
* Metric accuracy check: Do automated results match manual analysis?
* Voice recognition task: Blind identification of authentic vs. AI-edited excerpts
* Semi-structured interview: Perceived utility of metrics for preserving voice in their own writing
E. Analysis
* Quantitative: Paired-samples t-tests comparing baseline and AI-edited metrics; inter-rater reliability for manual coding
* Qualitative: Thematic analysis of interview transcripts (voice awareness, tool usefulness)
Benefits:
i. Pedagogical: concrete tools for teaching voice awareness.
ii. Institutional: a framework for authorship documentation.
iii. Theoretical: empirical grounding for L2 identity research.
iv. Practical: critical engagement tools for L2 learners using AI assistance.
Limitations:
The proposed tool is a prototype, not a production system. Voice preservation metrics require further validation. Audit reports are conceptual and lack institutional recognition.
Conclusion:
This thesis argues for measurable voice preservation in AI-assisted L2 writing. The goal is to make visible what is currently invisible and to make learners informed choice about what they keep and what they lose.